{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.models as torchvision_models\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from attnloss import AttnLoss\n",
    "from contrastloss import ContrastLoss\n",
    "from LSWEncoderOnly import EncoderOnly\n",
    "from LSWNet import LSWNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderOnly(nn.Module):\n",
    "    def __init__(self, hidden_size, kernel_size=3):\n",
    "        super(EncoderOnly, self).__init__()\n",
    "        \n",
    "        # 使用原始编码器部分的结构\n",
    "        self.conv_encoder1 = nn.Sequential(\n",
    "            nn.BatchNorm1d(1),\n",
    "            nn.Conv1d(1, hidden_size, kernel_size=kernel_size, padding=kernel_size // 2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.t_encoder1 = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=hidden_size, nhead=4, batch_first=True),\n",
    "            num_layers=1\n",
    "        )\n",
    "\n",
    "        self.conv_encoder2 = nn.Sequential(\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.Conv1d(hidden_size, hidden_size, kernel_size=kernel_size, padding=kernel_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.t_encoder2 = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=hidden_size, nhead=4, batch_first=True),\n",
    "            num_layers=1\n",
    "        )\n",
    "\n",
    "        self.conv_encoder3 = nn.Sequential(\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.Conv1d(hidden_size, hidden_size, kernel_size=kernel_size, padding=kernel_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.t_encoder3 = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=hidden_size, nhead=4, batch_first=True),\n",
    "            num_layers=1\n",
    "        )\n",
    "        \n",
    "        self.T_encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=hidden_size, nhead=4, batch_first=True),\n",
    "            num_layers=3\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 编码器部分的前向传播与原始模型相同\n",
    "        B, T, N, _ = x.size()\n",
    "        \n",
    "        x = x.view(B * T, 1, N)\n",
    "        x1 = self.conv_encoder1(x)\n",
    "        x1 = x1.transpose(1, 2)\n",
    "        x1 = self.t_encoder1(x1)\n",
    "        x1 = x1.transpose(1, 2)\n",
    "        \n",
    "        x2 = self.conv_encoder2(x1)\n",
    "        x2 = x2.transpose(1, 2)\n",
    "        x2 = self.t_encoder2(x2)\n",
    "        x2 = x2.transpose(1, 2)\n",
    "        \n",
    "        x3 = self.conv_encoder3(x2)\n",
    "        x3 = x3.transpose(1, 2)\n",
    "        x3 = self.t_encoder3(x3)\n",
    "        x3 = x3.transpose(1, 2)\n",
    "        \n",
    "        x = x3.view(B, T, -1, x3.size(-1))\n",
    "        x = x.permute(0, 2, 1, 3).contiguous().view(B * N // 8, T, -1)\n",
    "        x_encoder = self.T_encoder(x)\n",
    "        \n",
    "        return x_encoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSWNet(nn.Module):\n",
    "    def __init__(self, hidden_size, kernel_size=3):\n",
    "        super(LSWNet, self).__init__()\n",
    "        \n",
    "        # Pool first\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool1d(1)\n",
    "        # Encoder Layers\n",
    "        self.conv_encoder1 = nn.Sequential(\n",
    "            nn.BatchNorm1d(1),\n",
    "            nn.Conv1d(1, hidden_size, kernel_size=kernel_size, padding=kernel_size // 2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.conv1= nn.Sequential(\n",
    "            nn.ConvTranspose1d(hidden_size, hidden_size, kernel_size=2, stride=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv2= nn.Sequential(\n",
    "            nn.ConvTranspose1d(hidden_size, hidden_size, kernel_size=2, stride=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.ConvTranspose1d(hidden_size, 1, kernel_size=2, stride=2),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        # Input (B, T, N, C)\n",
    "        B, T, N, _ = x.size()\n",
    "        x = x.permute(0, 2, 3, 1).contiguous()  # 将形状从 (B, T, N, 1) 改为 (B, N, 1, T)\n",
    "        x = x.view(B * N, -1, T)  # 将形状从 (B, N, 1, T) 改为 (B * N, 1, T)\n",
    "        # x = alpha_0 * self.avg_pool(output) + alpha_1 * self.max_pool(output)\n",
    "        x = self.avg_pool(x).view(B, N, -1).permute(0, 2, 1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        #x格式是(B,1,8N)\n",
    "        x = self.sigmoid(x)\n",
    "        x = x.transpose(1, 2)\n",
    "       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "point_cloud_data = np.load(data_path) \n",
    "n, N = point_cloud_data.shape\n",
    "\n",
    "# 定义 T 的长度\n",
    "T = 5\n",
    "assert T % 2 == 1, \"T 必须是奇数，以便能对称地选择前后帧\"\n",
    "padding = T // 2  # 对称 padding，用于从每帧提取前后相邻帧\n",
    "valid_frames = n - 2 * padding  # 可用帧数量\n",
    "\n",
    "# 创建 Dataset 实例\n",
    "dataset = PointCloudSequenceDataset(point_cloud_data, T=T)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# 实例化并加载保存的编码器权重\n",
    "encoder_only_model = EncoderOnly(hidden_size=hidden_size, kernel_size=kernel_size)\n",
    "encoder_params_path = \"/share/home/tj90055/dhj/Self_Feature_LO/src/point_cloud_processing/model/LSencoder/encoder_params001.pth\"\n",
    "encoder_state_dict = torch.load(encoder_params_path, map_location=device)\n",
    "\n",
    "# 加载参数到模型\n",
    "encoder_only_model.conv_encoder1.load_state_dict(encoder_state_dict[\"conv_encoder1\"])\n",
    "encoder_only_model.t_encoder1.load_state_dict(encoder_state_dict[\"t_encoder1\"])\n",
    "encoder_only_model.conv_encoder2.load_state_dict(encoder_state_dict[\"conv_encoder2\"])\n",
    "encoder_only_model.t_encoder2.load_state_dict(encoder_state_dict[\"t_encoder2\"])\n",
    "encoder_only_model.conv_encoder3.load_state_dict(encoder_state_dict[\"conv_encoder3\"])\n",
    "encoder_only_model.t_encoder3.load_state_dict(encoder_state_dict[\"t_encoder3\"])\n",
    "encoder_only_model.T_encoder.load_state_dict(encoder_state_dict[\"T_encoder\"])\n",
    "encoder_only_model = encoder_only_model.to(device)\n",
    "\n",
    "LSWNet_model = LSWNet(hidden_size=hidden_size, kernel_size=kernel_size)\n",
    "LSWNet_model_path = \"/share/home/tj90055/dhj/Self_Feature_LO/src/point_cloud_processing/model/LSencoder/LSWNet_params001.pth\"\n",
    "LSWNet_state_dict = torch.load(LSWNet_model_path, map_location=device)\n",
    "LSWNet_model.load_state_dict(LSWNet_state_dict)\n",
    "LSWNet_model = LSWNet_model.to(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_index = random.randint(0, len(dataset) - 1)\n",
    "random_sample = dataset[random_index]\n",
    "encoder_only_model.eval()\n",
    "with torch.no_grad():\n",
    "    encoder_output = encoder_only_model(random_sample.unsqueeze(0).to(device))\n",
    "    \n",
    "x_encoder = encoder_output.view(B, N//8, T, -1).permute(0, 2, 1, 3).contiguous()\n",
    "LSWNet_model.eval()\n",
    "with torch.no_grad():\n",
    "    LSWNet_output = LSWNet_model(x_encoder)\n",
    "\n",
    "weights = LSWNet_output.squeeze(0)\n",
    "data = random_sample[:, :, 2].squeeze(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def get_image(points):\n",
    "    x, y = [], []\n",
    "    for k in range(len(points)):\n",
    "        theta = k / 810 * np.pi\n",
    "        px = - points[k] * np.cos(theta)\n",
    "        py = points[k] * np.sin(theta)\n",
    "        x.append(px)\n",
    "        y.append(py)\n",
    "    return x, y\n",
    "\n",
    "# def get_color(attn):\n",
    "#     c = []\n",
    "#     for a in attn:\n",
    "#         if a < 0.2:\n",
    "#             c.append(\"#fff143\")\n",
    "#         elif a < 0.5:\n",
    "#             c.append(\"#ffb61e\")\n",
    "#         elif a < 0.75:\n",
    "#             c.append(\"#ff7500\")\n",
    "#         else:\n",
    "#             c.append(\"r\")\n",
    "#     return c\n",
    "\n",
    "def get_color(attn):\n",
    "    c = []\n",
    "    for a in attn:\n",
    "        if a < 0.1:\n",
    "            c.append(\"#ffff00\")  # 黄色\n",
    "        elif a < 0.3:\n",
    "            c.append(\"#ffcc00\")  # 深橙色\n",
    "        elif a < 0.5:\n",
    "            c.append(\"#ff9900\")  # 橙色\n",
    "        elif a < 0.7:\n",
    "            c.append(\"#ff6600\")  # 浅橙色\n",
    "        elif a < 0.9:\n",
    "            c.append(\"#ff3300\")  # 深红色\n",
    "        else:\n",
    "            c.append(\"#ff0000\")  # 红色\n",
    "    return c\n",
    "\n",
    "# def get_shape(attn):\n",
    "#     s = []\n",
    "#     for a in attn:\n",
    "#         if a < 0.2:\n",
    "#             s.append(0.3)\n",
    "#         elif a < 0.5:\n",
    "#             s.append(0.8)\n",
    "#         elif a < 0.75:\n",
    "#             s.append(1.5)\n",
    "#         else:\n",
    "#             s.append(2)\n",
    "#     return s\n",
    "\n",
    "def get_shape(attn):\n",
    "    s = []\n",
    "    for a in attn:\n",
    "        if a < 0.1:\n",
    "            s.append(0.8*2)  # 非常小\n",
    "        elif a < 0.3:\n",
    "            s.append(1.6*2)  # 较小\n",
    "        elif a < 0.5:\n",
    "            s.append(2.4*2)  # 小\n",
    "        elif a < 0.7:\n",
    "            s.append(3.2*2)  # 中等\n",
    "        elif a < 0.9:\n",
    "            s.append(4.0*2)  # 大\n",
    "        else:\n",
    "            s.append(4.8*2)  # 非常大\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 16))\n",
    "\n",
    "\n",
    "\n",
    "x, y = get_image(data)\n",
    "c = get_color(weights)\n",
    "s = get_shape(weights)\n",
    "ax=plt.subplot(221+i)\n",
    "plt.title(\"Scene\" , fontsize=38)\n",
    "plt.scatter(x, y, s=s, c=c)\n",
    "# 获取当前子图的坐标轴对象\n",
    "ax = plt.gca()\n",
    "\n",
    "# 设置横纵坐标轴标签的字体大小\n",
    "ax.set_xlabel('', fontsize=30)\n",
    "ax.set_ylabel('', fontsize=30)\n",
    "\n",
    "# 设置横纵坐标轴刻度标签的字体大小\n",
    "for label in ax.get_xticklabels() + ax.get_yticklabels():\n",
    "    label.set_fontsize(32)\n",
    "\n",
    "    \n",
    "    \n",
    "# # 调整子图之间的间距\n",
    "# plt.subplots_adjust(wspace=0.2, hspace=0.2)  # wspace 控制水平间距，hspace 控制垂直间距\n",
    "# # plt.savefig(\"Effectiveness Analysis5.\")\n",
    "# # plt.savefig(\"Effectiveness Analysis5.pdf\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
